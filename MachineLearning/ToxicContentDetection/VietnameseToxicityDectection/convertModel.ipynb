{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7974d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import T5ForSequenceClassification, AutoTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TorchScript model saved as model.pt\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load m√¥ h√¨nh\n",
    "model_path = os.path.abspath(\"../VietnameseToxicityDectection\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_path, local_files_only=True)\n",
    "base_model.eval()\n",
    "\n",
    "# G√≥i l·∫°i model ƒë·ªÉ ch·ªâ tr·∫£ v·ªÅ logits\n",
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(WrappedModel, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.logits  # Ch·ªâ l·∫•y logits ƒë·ªÉ d·ªÖ trace/script\n",
    "\n",
    "# G√≥i model\n",
    "wrapped_model = WrappedModel(base_model)\n",
    "wrapped_model.eval()\n",
    "\n",
    "# T·∫°o input m·∫´u\n",
    "text = \"ƒê√¢y l√† m·ªôt v√≠ d·ª•.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Trace\n",
    "traced_model = torch.jit.trace(wrapped_model, (inputs[\"input_ids\"], inputs[\"attention_mask\"]))\n",
    "traced_model.save(\"model.pt\")\n",
    "print(\"‚úÖ TorchScript model saved as model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bd2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Text: Ch√∫c b·∫°n m·ªôt ng√†y t·ªët l√†nh!\n",
      "‚û°Ô∏è Prediction: NON-TOXIC (score=0.9999)\n",
      "\n",
      "üìù Text: ƒê·ªì ngu d·ªët, kh√¥ng bi·∫øt g√¨ c·∫£.\n",
      "‚û°Ô∏è Prediction: TOXIC (score=0.9957)\n",
      "\n",
      "üìù Text: Bu·ªïi thuy·∫øt tr√¨nh h√¥m nay th·∫≠t tuy·ªát v·ªùi.\n",
      "‚û°Ô∏è Prediction: NON-TOXIC (score=0.9984)\n",
      "\n",
      "üìù Text: M√†y l√† ƒë·ªì v√¥ h·ªçc, c√∫t ƒëi!\n",
      "‚û°Ô∏è Prediction: TOXIC (score=0.9761)\n",
      "\n",
      "üìù Text: C√°i nh√† n√†y r·∫•t t·ªá\n",
      "‚û°Ô∏è Prediction: TOXIC (score=0.6490)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "model_path = os.path.abspath(\"../VietnameseToxicityDectection\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load TorchScript model\n",
    "model = torch.jit.load(\"model.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Test data\n",
    "test_texts = [\n",
    "    \"Ch√∫c b·∫°n m·ªôt ng√†y t·ªët l√†nh!\",\n",
    "    \"ƒê·ªì ngu d·ªët, kh√¥ng bi·∫øt g√¨ c·∫£.\",\n",
    "    \"Bu·ªïi thuy·∫øt tr√¨nh h√¥m nay th·∫≠t tuy·ªát v·ªùi.\",\n",
    "    \"M√†y l√† ƒë·ªì v√¥ h·ªçc, c√∫t ƒëi!\",\n",
    "    \"C√°i nh√† n√†y r·∫•t t·ªá\"\n",
    "]\n",
    "\n",
    "# X·ª≠ l√Ω input v√† ch·∫°y m√¥ h√¨nh\n",
    "for text in test_texts:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
    "        probs = torch.softmax(logits, dim=-1)  # softmax v√¨ output c√≥ 2 l·ªõp\n",
    "        pred = torch.argmax(probs, dim=-1).item()  # l·∫•y index l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t\n",
    "        label = \"TOXIC\" if pred == 1 else \"NON-TOXIC\"\n",
    "        print(f\"üìù Text: {text}\\n‚û°Ô∏è Prediction: {label} (score={probs[0, pred]:.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e2b7db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36096, 768])\n",
      "(36096, 768)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.jit.load(\"model.pt\")\n",
    "\n",
    "# In shape embedding\n",
    "print(model.model.transformer.shared.weight.shape)  # v√≠ d·ª•: torch.Size([vocab_size, embedding_dim])\n",
    "\n",
    "# N·∫øu mu·ªën l·∫•y m·∫£ng numpy\n",
    "embedding_weights = model.model.transformer.shared.weight.detach().cpu().numpy()\n",
    "print(embedding_weights.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea08ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ONNX model exported as model.onnx\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o input m·∫´u gi·ªëng v·ªõi input cho model\n",
    "text = \"ƒê√¢y l√† m·ªôt v√≠ d·ª•.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "torch.onnx.export(\n",
    "    wrapped_model,\n",
    "    (inputs[\"input_ids\"], inputs[\"attention_mask\"]),\n",
    "    \"model.onnx\",\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "        \"logits\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=14  # ƒê·ªïi sang 14 ƒë·ªÉ h·ªó tr·ª£ triu v√† nhi·ªÅu operator m·ªõi h∆°n\n",
    ")\n",
    "print(\"‚úÖ ONNX model exported as model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd111a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Text: Ch√∫c b·∫°n m·ªôt ng√†y t·ªët l√†nh!\n",
      "‚û°Ô∏è Prediction: NON-TOXIC (score=0.9999)\n",
      "\n",
      "üìù Text: ƒê·ªì ngu d·ªët, kh√¥ng bi·∫øt g√¨ c·∫£.\n",
      "‚û°Ô∏è Prediction: TOXIC (score=0.9957)\n",
      "\n",
      "üìù Text: Bu·ªïi thuy·∫øt tr√¨nh h√¥m nay th·∫≠t tuy·ªát v·ªùi.\n",
      "‚û°Ô∏è Prediction: NON-TOXIC (score=0.9984)\n",
      "\n",
      "üìù Text: M√†y l√† ƒë·ªì v√¥ h·ªçc, c√∫t ƒëi!\n",
      "‚û°Ô∏è Prediction: TOXIC (score=0.9761)\n",
      "\n",
      "üìù Text: C√°i nh√† n√†y r·∫•t t·ªá\n",
      "‚û°Ô∏è Prediction: TOXIC (score=0.6490)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load tokenizer\n",
    "model_path = os.path.abspath(\"../VietnameseToxicityDectection\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load ONNX model\n",
    "onnx_model_path = \"model.onnx\"\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Test data\n",
    "test_texts = [\n",
    "    \"Ch√∫c b·∫°n m·ªôt ng√†y t·ªët l√†nh!\",\n",
    "    \"ƒê·ªì ngu d·ªët, kh√¥ng bi·∫øt g√¨ c·∫£.\",\n",
    "    \"Bu·ªïi thuy·∫øt tr√¨nh h√¥m nay th·∫≠t tuy·ªát v·ªùi.\",\n",
    "    \"M√†y l√† ƒë·ªì v√¥ h·ªçc, c√∫t ƒëi!\",\n",
    "    \"C√°i nh√† n√†y r·∫•t t·ªá\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"np\", padding=True, truncation=True)\n",
    "\n",
    "    # √âp ki·ªÉu sang int64 v√¨ ONNX Runtime y√™u c·∫ßu\n",
    "    input_feed = {\n",
    "        \"input_ids\": inputs[\"input_ids\"].astype(np.int64),\n",
    "        \"attention_mask\": inputs[\"attention_mask\"].astype(np.int64)\n",
    "    }\n",
    "\n",
    "    # Run inference\n",
    "    logits = ort_session.run(output_names=[\"logits\"], input_feed=input_feed)[0]  # [batch_size, num_labels]\n",
    "\n",
    "    # T√≠nh softmax ƒë·ªÉ ra x√°c su·∫•t\n",
    "    probs = np.exp(logits) / np.exp(logits).sum(axis=-1, keepdims=True)\n",
    "\n",
    "    pred = np.argmax(probs, axis=-1)[0]\n",
    "    label = \"TOXIC\" if pred == 1 else \"NON-TOXIC\"\n",
    "    print(f\"üìù Text: {text}\\n‚û°Ô∏è Prediction: {label} (score={probs[0, pred]:.4f})\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
