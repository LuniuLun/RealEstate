{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690188ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DUC VAN\\miniconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model đã được tải: T5ForSequenceClassification\n",
      "Tokenizer đã được tải: T5TokenizerFast\n",
      "Văn bản: 'Chúc bạn một ngày tốt lành!'\n",
      "Kết quả: non-toxic (Điểm toxic: 0.0001)\n",
      "--------------------------------------------------\n",
      "Văn bản: 'Đồ ngu dốt, không biết gì cả.'\n",
      "Kết quả: toxic (Điểm toxic: 0.9957)\n",
      "--------------------------------------------------\n",
      "Văn bản: 'Buổi thuyết trình hôm nay thật tuyệt vời.'\n",
      "Kết quả: non-toxic (Điểm toxic: 0.0016)\n",
      "--------------------------------------------------\n",
      "Văn bản: 'Mày là đồ vô học, cút đi!'\n",
      "Kết quả: toxic (Điểm toxic: 0.9761)\n",
      "--------------------------------------------------\n",
      "Văn bản: 'Cái nhà này rất tệ'\n",
      "Kết quả: toxic (Điểm toxic: 0.6490)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Cài đặt các thư viện cần thiết\n",
    "# Uncomment dòng dưới nếu chưa cài đặt transformers\n",
    "\n",
    "# Cell 2: Import các thư viện\n",
    "import torch\n",
    "from transformers import T5ForSequenceClassification, AutoTokenizer\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Cell 3: Tải tokenizer và model\n",
    "# Đường dẫn tới thư mục chứa các file model (.bin, .model, config.json, etc.)\n",
    "model_dir = \".\"  # Thay đổi nếu cần\n",
    "\n",
    "# Tải tokenizer từ local files\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# Tải model T5ForSequenceClassification từ file pytorch_model.bin\n",
    "model = T5ForSequenceClassification.from_pretrained(\n",
    "    model_dir,\n",
    "    local_files_only=True\n",
    ")\n",
    "model.eval()  # Chuyển sang chế độ evaluation\n",
    "\n",
    "# Cell 4: Hàm dự đoán\n",
    "def predict_toxicity(text, tokenizer, model):\n",
    "    # Với mô hình T5, đôi khi cần prefix\n",
    "    # Nếu model đã được fine-tune với một prefix cụ thể, hãy sử dụng nó\n",
    "    # Ví dụ: prefix = \"phân loại: \"\n",
    "    # text_with_prefix = prefix + text\n",
    "    \n",
    "    # Tokenize văn bản đầu vào\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Thực hiện dự đoán\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "        predictions = torch.argmax(probabilities, dim=-1)\n",
    "    \n",
    "    # Lấy kết quả và xác suất\n",
    "    prediction = predictions.item()\n",
    "    probability = probabilities[0][prediction].item()\n",
    "    \n",
    "    # Map label index to label name (0: non-toxic, 1: toxic)\n",
    "    # Lưu ý: Bạn cần xác nhận thứ tự này dựa trên cách model được train\n",
    "    label_map = {0: \"non-toxic\", 1: \"toxic\"}\n",
    "    predicted_label = label_map[prediction]\n",
    "    \n",
    "    return {\n",
    "        \"label\": predicted_label,\n",
    "        \"probability\": probability,\n",
    "        \"toxic_score\": probabilities[0][1].item() if probabilities.shape[1] > 1 else probability\n",
    "    }\n",
    "\n",
    "# Cell 5: Kiểm tra với một số ví dụ\n",
    "# Thêm cell này để kiểm tra xem model load thành công chưa trước khi dự đoán\n",
    "print(f\"Model đã được tải: {model.__class__.__name__}\")\n",
    "print(f\"Tokenizer đã được tải: {tokenizer.__class__.__name__}\")\n",
    "\n",
    "# Cell 6: Kiểm tra với một số ví dụ\n",
    "test_texts = [\n",
    "    \"Chúc bạn một ngày tốt lành!\",\n",
    "    \"Đồ ngu dốt, không biết gì cả.\",\n",
    "    \"Buổi thuyết trình hôm nay thật tuyệt vời.\",\n",
    "    \"Mày là đồ vô học, cút đi!\",\n",
    "    \"Cái nhà này rất tệ\",\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    result = predict_toxicity(text, tokenizer, model)\n",
    "    print(f\"Văn bản: '{text}'\")\n",
    "    print(f\"Kết quả: {result['label']} (Điểm toxic: {result['toxic_score']:.4f})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Cell 7: Hàm để sử dụng model trong ứng dụng thực tế\n",
    "def detect_toxic_content(text):\n",
    "    \"\"\"\n",
    "    Hàm tiện ích để sử dụng trong ứng dụng\n",
    "    \n",
    "    Args:\n",
    "        text (str): Văn bản tiếng Việt cần kiểm tra\n",
    "        \n",
    "    Returns:\n",
    "        dict: Kết quả phân loại với nhãn và điểm số\n",
    "    \"\"\"\n",
    "    return predict_toxicity(text, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b54afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Văn bản: 'Chúc bạn một ngày tốt lành!'\n",
      "Token IDs: [8128, 1113, 68, 198, 1387, 3481, 35993, 1]\n",
      "Độ dài token: 8 (Vượt 512?: Không)\n",
      "Kết quả: non-toxic (Điểm toxic: 0.0001)\n",
      "--------------------------------------------------\n",
      "Văn bản: 'Đồ ngu dốt, không biết gì cả.'\n",
      "Token IDs: [1287, 5784, 25975, 35790, 129, 300, 1080, 251, 35792, 1]\n",
      "Độ dài token: 10 (Vượt 512?: Không)\n",
      "Kết quả: toxic (Điểm toxic: 0.9957)\n",
      "--------------------------------------------------\n",
      "Văn bản: 'Buổi thuyết trình hôm nay thật tuyệt vời.'\n",
      "Token IDs: [5856, 1736, 498, 1045, 714, 1655, 2498, 5137, 35792, 1]\n",
      "Độ dài token: 10 (Vượt 512?: Không)\n",
      "Kết quả: non-toxic (Điểm toxic: 0.0016)\n",
      "--------------------------------------------------\n",
      "Văn bản: 'Mày là đồ vô học, cút đi!'\n",
      "Token IDs: [10297, 49, 1333, 1244, 268, 35790, 15241, 352, 35993, 1]\n",
      "Độ dài token: 10 (Vượt 512?: Không)\n",
      "Kết quả: toxic (Điểm toxic: 0.9761)\n",
      "--------------------------------------------------\n",
      "Văn bản: 'Cái nhà này rất tệ'\n",
      "Token IDs: [2797, 233, 118, 726, 2235, 1]\n",
      "Độ dài token: 6 (Vượt 512?: Không)\n",
      "Kết quả: toxic (Điểm toxic: 0.6490)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Kiểm tra với một số ví dụ, bổ sung in token IDs và kiểm tra độ dài\n",
    "for text in test_texts:\n",
    "    # Tokenize câu, trả về token IDs\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    token_ids = inputs[\"input_ids\"][0].tolist()  # Lấy token ID dạng list\n",
    "    \n",
    "    # Kiểm tra độ dài token IDs\n",
    "    length = len(token_ids)\n",
    "    exceeds_max_len = length > 512\n",
    "    \n",
    "    print(f\"Văn bản: '{text}'\")\n",
    "    print(f\"Token IDs: {token_ids}\")\n",
    "    print(f\"Độ dài token: {length} (Vượt 512?: {'Có' if exceeds_max_len else 'Không'})\")\n",
    "    \n",
    "    # Dự đoán toxicity\n",
    "    result = predict_toxicity(text, tokenizer, model)\n",
    "    print(f\"Kết quả: {result['label']} (Điểm toxic: {result['toxic_score']:.4f})\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
